Soon your fridge will be able to buy your food on Amazon, having noticed what you liked on Facebook and Instagram. Cybersecurity is crucial for this to happen; to make sure that, while our food preferences are being noted, our identity is not stolen, credit cards not cloned, and our devices are not tampered with by malicious actors out to steal data or modify a machine’s behaviour. As the Fourth Industrial Revolution progresses and the integration and interaction of different technologies is used to improve individual and environmental wellbeing, cybersecurity will be ever more important. In 2015, the UN identified 17 Sustainable Development Goals (SDGs) to be achieved by 2030 – ranging from eradicating poverty and guaranteeing stability and peace to fighting discrimination and climate change. Digital technologies, particularly the internet of things (IoT) and artificial intelligence (AI), can facilitate efforts to achieve the SDGs. For example, AI can help detect malnutrition using photographs of individuals living in a given area. Here, too, cybersecurity is crucial. Should pictures of those individuals be stolen or the AI model becomes corrupted, the use of AI to fight starvation would become problematic. Cybersecurity underpins trust in, and thus the adoption of, digital technologies for humanitarian and environmental purposes. It does not come as a surprise, therefore, that the value of the cybersecurity market is estimated to grow from $120 billion in 2019 to $300 billion by 2024. It is more surprising that, while efforts and investment to improve cybersecurity continue to grow, security developments lag behind the pace of the malicious use of digital technologies. Cyber threats are escalating in frequency, impact and sophistication. The World Economic Forum’s Global Risks Report 2019 ranked cyberattacks among the top-five risks. At a global level, cybercrime causes multibillion dollar losses to business; the average cost of cybercrime for an organization has increased from $11.7 million in 2017 to $13.0 million. That year, the WannaCry and NotPetya incidents showed that attacks targeting the cyber component of infrastructures (such as power plants), services (such as banks or hospitals servers) and tools and devices (mobiles and personal computers, for example) have great disruptive potential and can cause serious damage. The lack of effective cybersecurity measures has a potential knock-on effect on the Fourth Industrial Revolution, and on the development of information societies around the globe. Two aspects are particularly relevant: stability and trust. Without effective security measures in place, cyberthreats may undermine the stability of information societies, making digital technologies a source of risk more than a source of development. At the same time, a lack of security around digital technologies will erode users’ trust, which will in turn cripple adoption and hinder innovation. Cybersecurity is an essential resource of information societies and improving it is vital to fostering societal development, technological progress, and harnessing the potential of digital technologies to deliver outcomes that are beneficial to society. The term cybersecurity covers a vast domain. It ranges from designing systems that are robust and can withstand attacks, to the design of methods and systems for threat and anomaly detection (TAD), to guaranteeing systems’ resilience and defining systems’ responses to attacks. In societies that depend on digital infrastructure to function, systems’ robustness is an essential requirement. But improving it is a costly process. It requires accurate design, code verification and validation, testing and probing for vulnerabilities. This makes cybersecurity a club good – namely, a good that is not exhausted by its use (non-rivalrous), but whose access is regulated by its cost. The escalation of cyberthreats indicates that this approach is ineffective, if not problematic, because market dynamics and the costs associated with improving systems’ robustness lead to an uneven distribution of cybersecurity measures. Consider, for example, the IoT. The robustness of digital end-point devices has an impact on their costs, to the extent that producers may sacrifice robustness in the interest of retaining commercial competitiveness. In 2018, a Symantec study reported an average of 5,200 attacks per month on IoT devices. As IoT increasingly pervades our private and public environments, its vulnerabilities may favour severe security and safety from threats. The question, then, is how do we develop and regulate the design of robust systems in an effective way? Clearly, engineering robust systems has both a direct and indirect impact on the public in information societies. It enables critical national infrastructures and services to work, allows citizens to perform their daily routines, and can favour the socially beneficial outcomes of digital technologies. For these reasons, cybersecurity should not be framed and managed as a club good – it should be treated as a public good, that is, a non-rivalrous good that is also non-excludable (which means no user can prevent others from using it). Managing costs is key to developing systems’ robustness as a public good. This does not mean that systems’ robustness need to come free of charge, but it is essential that the costs do not become a deciding factor in determining access. The key point here is to ensure that all users have access to digital technologies whose robustness is adequate to the purpose and the context of deployment. This point can be clarified using two analogies: streetlights and national defence. These are two typical public goods; both come at a cost, but all citizens of a state access them independently of these costs, and they all contribute to maintain these goods by paying taxes. In the same way, cybersecurity can function as a public good if its costs are shared equitably among the relevant stakeholders. One implication of this approach is that the public sector will have to shoulder some of the costs of cybersecurity: this may include, for example, costs related to the setting of standards and certification procedures, as well as costs associated with testing and verifying technologies. But managing cybersecurity as a public good would also yield three important advantages: systemic approaches to security, shared responsibilities among the different stakeholders, and fostering collaboration. Systemic approach: The management of a public good requires considering direct and indirect externalities, as well as medium and long-term consequences. This favours approaches to cybersecurity that focus on interdependencies among the security of different, but connected, technologies, their impact on the context of deployment and on the relevant public interest at stake. Shared responsibilities: Management of cybersecurity as a public good calls for collaboration between the private and the public sectors to ensure that systems’ robustness is designed to meet the public interest. It is up to the public sector to set standards, certification and testing and verification procedures capable of ensuring that a sufficient level of security is maintained. At the same time, the private sector bears responsibility for designing robust systems and developing and improving new cybersecurity methods for the services and products they offer, as well as for collaborating with the public sector around controlling and testing mechanisms. Envisaging systems’ robustness as a public good also places some responsibility on the user in terms of their cyber hygiene practices. The distribution of responsibilities among the various stakeholders together with the need to consider direct and indirect externalities is likely to foster collaboration and information sharing. Sharing information about the vulnerabilities of different systems involved in the same supply chain, for example, will become crucial for the private sector to guarantee systems’ robustness and to learn from its peers. At the same time, the public sector may support this by including information-sharing and collaboration as part of its capability-building initiatives and procedures. Post-Fourth Industrial Revolution societies will assess the success of this revolution in terms of its impact on the development of tolerant, open, pluralistic, stable and mature information societies. The Platform for Shaping the Future of Cybersecurity and Digital Trust is committed to securing our shared digital future, ensuring that secure digital transformation will enable the global economy and society to prosper. Framing cybersecurity as a public good would be decisive for the attainment of this prosperity, for it will help to hamper the escalation dynamics of cyberthreats, improve the overall security of our societies and their stability while maintaining focus overall on the public interest. Mariarosaria TaddeoResearch Fellow and Deputy Director, Digital Ethics Lab, Oxford Internet Institute, University of Oxford and Francesca BoscoProject Lead, Cyber-Resilience, Centre for Cybersecurity, World Economic Forum This article was originally published on the World Economic Forum Blog. Read the original article.